# K‑Nearest Neighbor Classification (K‑최근린 분류)

## K-Nearest Neighbor Classification (K-최근린 분류) 설명

**1. 정의:**

K-Nearest Neighbor (KNN) 분류는 데이터 포인트를 가장 가까운 k개의 이웃에 기반하여 새로운 데이터 포인트의 범주를 예측하는 지도 학습 알고리즘입니다. 즉, 새로운 데이터가 기존 데이터와 유사한 이웃들과 얼마나 많은지를 기준으로 분류합니다.

**2. 핵심 개념:**

*   **거리 측정:** 데이터 포인트 간의 유사성을 판단하기 위해 거리 (유클리드 거리, 맨해튼 거리 등)를 사용합니다.
*   **k-값 (k):** KNN 알고리즘의 핵심 파라미터로, 이웃으로 고려할 데이터 포인트의 개수를 결정합니다.
*   **훈련 데이터:** KNN은 훈련 데이터에 의존하여 데이터의 패턴을 학습합니다.
*   **범주 (Label):** 훈련 데이터에 각 데이터 포인트에 대한 미리 정의된 범주 정보가 필요합니다.
*   **일반화 (Generalization):** 훈련 데이터에서 학습한 패턴을 바탕으로 새로운 데이터에 적용하여 예측하는 과정입니다.

**3. 작동 방식:**

1.  새로운 데이터 포인트가 주어질 때, KNN 알고리즘은 훈련 데이터셋의 각 데이터 포인트와 새로운 데이터 포인트 간의 거리를 계산합니다.
2.  가장 가까운 k개의 이웃 (k개의 가장 가까운 이웃)을 찾습니다.
3.  가장 가까운 k개의 이웃의 범주를 집계합니다 (예: 다수결 원칙).
4.  새로운 데이터 포인트의 범주는 가장 흔하게 나타나는 이웃의 범주로 결정됩니다.

**4. 응용 분야:**

*   **이미지 분류:** 손글씨 숫자 인식, 얼굴 인식 등
*   **텍스트 분류:** 스팸 메일 필터링, 뉴스 기사 주제 분류 등
*   **의료 진단:** 질병 예측, 환자 분류 등
*   **추천 시스템:** 사용자의 선호도에 기반한 상품 추천 등
*   **생성물 분류:** 제품 종류별 분류

**5. 관련 용어:**

*   **지도 학습 (Supervised Learning):**  정답(레이블)이 있는 데이터를 이용하여 학습하는 기법입니다.
*   **분류 (Classification):**  데이터를 미리 정의된 범주로 나누는 작업입니다.
*   **클러스터링 (Clustering):**  데이터를 유사한 특성을 가진 그룹으로 묶는 작업입니다.
*   **유클리드 거리 (Euclidean Distance):** 두 데이터 포인트 간의 직선 거리를 계산하는 방법입니다.
*   **다수결 원칙 (Majority Voting):** 가장 많은 득표수를 얻은 범주를 선택하는 방법입니다.