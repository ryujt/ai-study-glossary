# Tokenization (토큰화)

## 토큰화 (Tokenization)

**1. 정의:**

토큰화는 텍스트 데이터를 더 작고 관리 가능한 단위인 "토큰"으로 나누는 과정입니다. 이 토큰은 단어, 서브워드, 심지어 문자 단위가 될 수 있습니다.

**2. 핵심 개념:**

*   **단어 (Word):**  토큰화의 가장 기본적인 단위로, 텍스트 내에서 의미 있는 단위를 나타냅니다.
*   **서브워드 (Subword):** 단어가 아닌, 더 작은 의미 단위로 쪼개는 방식입니다. 복합 단어 처리의 어려움을 줄입니다.
*   **임베딩 (Embedding):** 토큰을 고차원 공간에 표현하여 의미적 유사성을 파악하는 방법입니다.
*   **토큰 ID (Token ID):** 각 토큰에 할당된 고유한 숫자 식별자입니다. 모델이 토큰을 처리하는 데 사용됩니다.
*   **토큰화 전략 (Tokenization Strategy):** 어떤 방식으로 텍스트를 토큰으로 나누어야 하는지 결정하는 방법 (예: 단어 기반, 서브워드 기반).

**3. 작동 방식:**

*   **텍스트 입력:** 먼저 입력된 텍스트 데이터를 받습니다.
*   **분할 (Splitting):** 텍스트를 공백, 구두점, 혹은 사전 정의된 규칙에 따라 분할합니다.
*   **정제 (Cleaning):** 불필요한 문자를 제거하거나, 소문자로 변환하는 등 토큰을 정제합니다.
*   **토큰 생성 (Token Generation):**  분할 및 정제된 데이터를 기반으로 토큰을 생성합니다.
*   **토큰 ID 할당 (ID Assignment):** 각 생성된 토큰에 고유한 숫자 ID를 할당합니다.

**4. 응용 분야:**

*   **자연어 처리 (NLP):** 텍스트 데이터를 모델이 이해할 수 있는 형태로 변환하여 텍스트 분류, 감성 분석, 기계 번역 등에 활용됩니다.
*   **대규모 언어 모델 (LLM):**  GPT, BERT와 같은 LLM은 토큰화를 통해 텍스트를 이해하고 생성합니다.
*   **검색 엔진:**  사용자가 입력한 검색어를 토큰화하여 관련 문서 검색에 활용됩니다.
*   **챗봇:** 봇이 사용자의 질문을 이해하고 답변을 생성하는 데 사용됩니다.

**5. 관련 용어:**

*   **워드 임베딩 (Word Embedding):** 단어를 벡터 형태로 표현하는 방법.
*   **패딩 (Padding):**  입력 데이터의 길이를 맞춰주는 기술.
*   **범주화 (Categorization):** 데이터를 미리 정의된 범주로 분류하는 과정.
*   **계산 언어학 (Computational Linguistics):** 언어 데이터를 컴퓨터로 분석하고 처리하는 분야.
*   **모델 파라미터 (Model Parameter):**  머신러닝 모델의 학습 과정에서 조정되는 값.