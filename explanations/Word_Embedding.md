# Word Embedding (단어 임베딩)

## Word Embedding (단어 임베딩) 설명

**1. 정의:**

단어 임베딩은 단어를 고정된 의미를 가진 숫자 벡터로 표현하는 방법입니다. 이는 단어의 의미를 수치적으로 나타내어, 단어 간의 유사성을 계산하고 언어 모델링 및 자연어 처리 작업에 활용합니다.

**2. 핵심 개념:**

*   **고차원 데이터:** 단어는 고차원 데이터를 나타냅니다. 임베딩은 이러한 데이터를 저차원 벡터 공간에 표현합니다.
*   **유사성 측정:** 벡터 간의 유사성 (코사인 유사도 등)을 통해 단어 간 의미적 유사성을 파악할 수 있습니다.
*   **차원 축소:** 고차원 단어 표현을 저차원 벡터로 압축하여 계산 효율성을 높입니다.
*   **분산 표현:** 단어의 의미가 단일 벡터에 저장되는 것이 아니라, 벡터 공간 내의 여러 위치에 분산되어 표현됩니다.
*   **문맥 정보:** 일부 임베딩 모델은 단어의 문맥적 의미를 고려하여 벡터를 생성합니다.

**3. 작동 방식:**

1.  **데이터 수집:** 대량의 텍스트 데이터 (예: Wikipedia, 웹 문서)를 수집합니다.
2.  **모델 학습:** 수집된 데이터에 기반하여 단어 임베딩 모델을 학습시킵니다. 흔히 사용되는 모델로는 Word2Vec, GloVe, FastText 등이 있습니다.
3.  **벡터 생성:** 학습된 모델은 각 단어에 대해 고유한 숫자 벡터 (embedding vector)를 생성합니다.
4.  **벡터 활용:** 생성된 벡터를 바탕으로 단어 간 유사성 측정, 언어 모델링, 텍스트 분류 등 다양한 작업 수행합니다.

**4. 응용 분야:**

*   **의미 기반 검색:** 검색어의 의미를 기반으로 관련 문서 검색
*   **추천 시스템:** 사용자 행동 패턴 및 콘텐츠 유사성을 기반으로 상품/콘텐츠 추천
*   **텍스트 분류:** 문서의 주제나 감성을 분류
*   **기계 번역:** 단어 의미를 정확하게 반영하여 번역 품질 향상
*   **질의 응답 시스템:** 질문의 의미를 파악하고 관련 답변 검색

**5. 관련 용어:**

*   **Word2Vec:** 단어 임베딩을 위한 대표적인 모델 중 하나
*   **GloVe:** Word2Vec과 유사하지만, 단어 동시 발생 통계를 활용
*   **FastText:** Subword 정보 (단어의 일부분)를 활용하여 rare word 처리 성능 향상
*   **RNN (Recurrent Neural Network):** 시퀀스 데이터 (텍스트) 처리용 딥러닝 모델
*   **CNN (Convolutional Neural Network):** 이미지 처리에서 주로 사용되지만, 텍스트 분석에도 활용
