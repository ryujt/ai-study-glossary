# Pruning (가지치기/프루닝)

## 가지치기 (프루닝) 설명

**1. 정의:**

가지치기(프루닝)는 인공지능 모델의 성능을 향상시키기 위해 모델의 복잡성을 줄이는 기술입니다. 불필요하거나 중요하지 않은 연결(노드, 가중치)을 제거하여 모델의 효율성을 높이는 과정입니다.

**2. 핵심 개념:**

*   **과적합 (Overfitting):** 모델이 학습 데이터에 지나치게 적합하여 새로운 데이터에 대한 일반화 성능이 떨어지는 현상입니다.
*   **가중치 감소 (Weight Decay):** 모델의 가중치가 너무 커지는 것을 방지하고, 모델의 일반화 성능을 향상시키기 위해 가중치에 페널티를 부여하는 방법입니다.
*   **모델 복잡도 (Model Complexity):** 모델의 파라미터 수, 레이어 수 등 모델의 복잡도를 의미합니다.
*   **일반화 성능 (Generalization Performance):** 학습 데이터 외의 새로운 데이터에 대해 모델이 얼마나 잘 작동하는지를 나타내는 지표입니다.
*   **학습률 (Learning Rate):** 모델이 학습 과정에서 업데이트하는 비율을 결정하는 하이퍼파라미터입니다.

**3. 작동 방식:**

가지치기는 모델 학습 후 또는 학습 과정 중 수행될 수 있습니다. 주로 다음과 같은 방법으로 작동합니다.

*   **후 처리 가지치기 (Post-Training Pruning):** 이미 학습된 모델을 평가하여 중요하지 않은 연결(노드, 가중치)을 제거합니다. 일반적으로 중요하지 않은 연결의 가중치를 0으로 설정하거나 완전히 제거합니다.
*   **온라인 가지치기 (Online Pruning):** 모델 학습 과정에서 실시간으로 중요하지 않은 연결을 제거합니다. 학습률을 조정하여 모델이 중요한 연결에 집중하도록 유도합니다.

**4. 응용 분야:**

*   **이미지 분류:** 이미지 인식 모델의 크기를 줄여서 모바일 기기나 임베디드 시스템에서 활용합니다.
*   **자연어 처리 (NLP):** 텍스트 분류, 감성 분석 등의 모델의 효율성을 높입니다.
*   **추천 시스템:** 모델의 복잡도를 줄여서 빠른 예측 속도를 얻습니다.
*   **시계열 예측:**  모델의 정확도를 유지하면서 불필요한 파라미터를 제거하여 효율성을 높입니다.

**5. 관련 용어:**

*   **하이퍼파라미터 튜닝 (Hyperparameter Tuning):** 모델의 성능을 최적화하기 위해 학습률, 가중치 감소 비율 등 하이퍼파라미터를 조정하는 과정입니다.
*   **정규화 (Regularization):** 모델의 과적합을 방지하기 위해 사용되는 기술입니다. L1 정규화, L2 정규화 등이 있습니다.
*   **신경망 (Neural Network):** 인공 신경망을 기반으로 하는 모델입니다.
*   **손실 함수 (Loss Function):** 모델의 예측 값과 실제 값의 차이를 측정하는 함수입니다.
*   **경사 하강법 (Gradient Descent):** 손실 함수를 최소화하기 위해 사용되는 최적화 알고리즘입니다.