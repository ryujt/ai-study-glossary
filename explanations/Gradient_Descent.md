# Gradient Descent (기울기 하강)

**1. 정의:**

Gradient Descent (기울기 하강)은 머신러닝 모델의 손실 함수(Loss Function)를 최소화하기 위해 모델 파라미터를 반복적으로 조정하는 최적화 알고리즘입니다. 손실 함수는 모델의 예측 값과 실제 값 사이의 차이를 나타냅니다.

**2. 핵심 개념:**

*   **손실 함수 (Loss Function):** 모델 예측과 실제 값 사이의 오차를 측정하는 함수입니다. 목표는 이 손실 함수 값을 최소화하는 것입니다.
*   **기울기 (Gradient):** 손실 함수에 대한 파라미터 변화에 따른 변화율을 나타내는 벡터입니다. 즉, 가장 급격하게 증가하는 방향을 가리킵니다.
*   **학습률 (Learning Rate):**  각 반복에서 파라미터를 얼마나 조정할지를 결정하는 상수입니다. 너무 크면 최적점 주변을 계속 뛰어다니고, 너무 작으면 수렴 속도가 느려집니다.
*   **최적점 (Minimum):** 손실 함수 값이 최소가 되는 파라미터 값입니다. Gradient Descent는 이 최적점을 찾기 위해 반복적으로 동작합니다.

**3. 작동 방식:**

1.  **초기화:** 모델 파라미터를 임의의 값으로 초기화합니다.
2.  **기울기 계산:** 현재 파라미터 값에서 손실 함수의 기울기를 계산합니다.
3.  **파라미터 업데이트:** 기울기의 반대 방향으로 파라미터를 조정합니다. 조정량은 학습률에 의해 결정됩니다. (파라미터 = 파라미터 - 학습률 * 기울기)
4.  **반복:** 2번과 3번 단계를 손실 함수 값이 충분히 작아질 때까지 반복합니다.

**4. 응용 분야:**

*   **선형 회귀 (Linear Regression):** 모델의 계수(Coefficient)를 학습하여 최적의 선을 찾습니다.
*   **로지스틱 회귀 (Logistic Regression):** 분류 모델의 파라미터를 학습하여 정확도를 높입니다.
*   **신경망 (Neural Networks):**  딥러닝 모델의 가중치(Weight)를 학습하여 복잡한 패턴을 학습합니다.
*   **추천 시스템 (Recommender Systems):** 사용자 선호도를 기반으로 맞춤형 추천을 생성하기 위해 모델을 학습합니다.

**5. 관련 용어:**

*   **역전파 (Backpropagation):** 신경망에서 가중치를 업데이트하는 데 사용되는 알고리즘입니다.
*   **최대 가능도 추정 (Maximum Likelihood Estimation, MLE):** 모델 파라미터를 추정하는 방법입니다.
*   **경사 하강법 (Gradient Descent):**  Gradient Descent의 영어 용어입니다.
*   **수렴 (Convergence):** 손실 함수 값이 더 이상 줄어들지 않을 때, 즉 최적점에 도달했을 때의 상태를 의미합니다.
*   **반복적인 최적화 (Iterative Optimization):** Gradient Descent가 사용하는 최적화 방식의 일반적인 용어입니다.