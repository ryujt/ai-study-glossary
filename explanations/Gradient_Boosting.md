# Gradient Boosting (그래디언트 부스팅)

## Gradient Boosting (그래디언트 부스팅) 설명

**1. 정의:**

Gradient Boosting은 여러 개의 약한 학습기(일반적으로 결정 트리)를 순차적으로 학습시켜 예측 모델의 정확도를 높이는 앙상블 학습 기법입니다. 각 학습기는 이전 학습기가 제대로 예측하지 못한 부분, 즉 ‘잔차(residual)’를 예측하도록 학습됩니다.

**2. 핵심 개념:**

*   **잔차 (Residual):** 이전 학습기가 예측한 값과 실제 값의 차이. 각 새로운 학습기는 이 잔차를 보정하는 데 집중합니다.
*   **앙상블 (Ensemble):** 여러 개의 모델을 결합하여 단일 모델보다 더 나은 성능을 얻는 기법입니다.
*   **결정 트리 (Decision Tree):** 데이터를 특정 기준에 따라 분할하여 예측하는 모델입니다. Gradient Boosting에서는 일반적으로 이러한 결정 트리를 약한 학습기로 사용합니다.
*   **학습률 (Learning Rate):** 각 학습기가 얼마나 빠르게 학습할지 결정하는 하이퍼파라미터입니다.  낮은 학습률은 수렴 속도를 높이지만, 과적합 위험을 줄일 수 있습니다.
*   **미니 최대 사후 (Margin Error):**  모델이 잘못 예측하는 데이터의 양을 최소화하는 것을 목표로 합니다.

**3. 작동 방식:**

1.  초기 모델 (예: 평균값)을 생성합니다.
2.  훈련 데이터에 대한 예측 오차 (잔차)를 계산합니다.
3.  이 잔차를 예측하기 위해 새로운 결정 트리를 학습합니다. 이 트리는 잔차를 최소화하도록 학습됩니다.
4.  새로운 트리의 예측값을 원래 모델에 더합니다.
5.  새로운 모델을 사용하여 데이터를 다시 예측하고, 이 과정을 반복합니다.
6.  각 트리는 이전 트리의 오차를 수정하는 데 집중하므로, 점차 더 정확한 예측을 제공합니다.

**4. 응용 분야:**

*   **이미지 분류:** 사진 속 객체 식별
*   **사기 탐지:** 금융 거래에서 사기 행위 탐지
*   **추천 시스템:** 사용자에게 적합한 상품 또는 콘텐츠 추천
*   **의료 진단:** 질병 진단 및 예측
*   **자연어 처리:** 텍스트 분석, 번역 등

**5. 관련 용어:**

*   **랜덤 포레스트 (Random Forest):** Gradient Boosting과 유사하지만, 결정 트리를 학습할 때 부트스트랩핑과 랜덤 서브스페이스를 사용하여 다양성을 확보합니다.
*   **서포트 벡터 머신 (SVM):**  데이터를 분류하기 위한 경계를 찾는 알고리즘입니다.
*   **신경망 (Neural Network):** 인간 뇌의 작동 방식을 모방한 복잡한 모델입니다.
*   **랜덤 서브스페이스 (Random Subspace):** Gradient Boosting에서 각 결정 트리를 학습할 때 사용되는 기술로, 데이터의 일부 특징만 사용하여 학습함으로써 과적합을 방지합니다.
*   **부트스트랩핑 (Bootstrapping):** 훈련 데이터를 무작위로 추출하여 여러 개의 부트스트랩 샘플을 생성하는 기술입니다.