# Self‑Supervised Learning (자기지도 학습)

**자기지도 학습 (Self-Supervised Learning)**

1.  **정의:** 자기지도 학습은 레이블이 없는 데이터로부터 스스로 학습하는 방법입니다. 즉, 데이터 자체에 내재된 정보를 활용하여 학습 목표를 설정하고, 이를 통해 모델이 특징을 추출하고 표현을 학습합니다.

2.  **핵심 개념:**
    *   **데이터 활용:** 레이블이 없는 대량의 데이터를 활용합니다.
    *   **전직 학습 (Pre-training):**  대규모 데이터로 먼저 학습한 모델을 다른 작업에 재사용하는 방식입니다.
    *   **마스크 예측 (Masked Prediction):**  데이터의 일부를 가리고, 가려진 부분을 예측하도록 모델을 훈련합니다.
    *   **인과 관계 학습 (Causal Learning):** 데이터 내의 인과 관계를 학습합니다.
    *   **표현 학습 (Representation Learning):**  데이터의 핵심 특징을 효과적으로 표현하는 방법을 학습합니다.

3.  **작동 방식:**
    *   자기지도 학습은 일반적으로 다음과 같은 단계를 거칩니다.
        1.  **마스킹 (Masking):** 입력 데이터의 일부(예: 이미지의 일부 영역, 문장의 일부 단어)를 숨깁니다.
        2.  **예측 목표 설정:** 숨겨진 부분에 대한 예측 목표를 설정합니다. 예를 들어, 이미지의 숨겨진 부분의 텍스쳐를 예측하거나, 문장의 문맥을 기반으로 누락된 단어를 예측합니다.
        3.  **모델 훈련:** 모델은 예측 목표를 달성하기 위해 데이터의 나머지 부분과 상호 작용합니다. 모델은 예측 오류를 줄이기 위해 데이터의 특징과 패턴을 학습합니다.
        4.  **전이 학습 (Transfer Learning):**  자기지도 학습으로 사전 학습된 모델은 다른 다운스트림 작업(예: 이미지 분류, 객체 감지)에 전이 학습되어 추가적인 레이블링된 데이터 없이 높은 성능을 달성할 수 있습니다.

4.  **응용 분야:**
    *   **자연어 처리 (NLP):**  텍스트 마스크 예측, 텍스트 완성 등.
    *   **컴퓨터 비전 (Computer Vision):** 이미지 마스크 예측, 이미지 덴오프닝 등.
    *   **음성 인식:** 음성 데이터 마스킹 등을 통해 모델 학습.
    *   **생물 정보학:** 유전자 시퀀스 데이터 분석 등.

5.  **관련 용어:**
    *   **지도 학습 (Supervised Learning):**  레이블이 있는 데이터로 학습하는 방법.
    *   **비지도 학습 (Unsupervised Learning):**  레이블이 없는 데이터로부터 자체적으로 패턴을 학습하는 방법.
    *   **강화 학습 (Reinforcement Learning):**  환경과의 상호 작용을 통해 보상을 최대화하는 방법을 학습합니다.
    *   **전이 학습 (Transfer Learning):** 다른 작업에서 학습한 지식을 새로운 작업에 적용하는 방법.
    *   **인공 신경망 (Artificial Neural Network):**  인간의 뇌를 모방한 방식으로 작동하는 모델.